shared:
  system_profiles:
    train_default: ${oc.select:system.training,{}}
    infer_default: ${oc.select:system.inference,{}}
  data_transform_profiles:
    default:
      data_transform: ${oc.select:data.data_transform,null}
      image_transform: ${oc.select:data.image_transform,null}
      nnunet_preprocessing: ${oc.select:data.nnunet_preprocessing,null}
  inference_profiles:
    default: ${oc.select:inference,{}}

# BetaSeg Dataset - 3D Mitochondria Instance Segmentation with MedNeXt
# multi-channel-task learning: Signed Distance Transform (SDT) + Affinity
#
# This config uses MedNeXt for mitochondria instance segmentation with SDT-based approach:
#   - Output: Single channel SDT (tanh activation) - WeightedMSE loss
#   - SDT encodes both foreground/background AND instance separation in one channel
#   - Positive values = inside instances (distance to boundary)
#   - Negative values = outside instances (distance to nearest instance)
#
# MedNeXt Configuration:
#   - Deep supervision: CRITICAL for MedNeXt performance (5 scales)
#   - Kernel size: 3 for better context (recommended for instance segmentation)
#   - Size: S (~20-30M params) - small model for efficient training
#
# Instance Segmentation Pipeline:
#   SDT prediction → Watershed on SDT seeds → Instance IDs
#
# BetaSeg Dataset:
#   - High-resolution EM (16x16x16 nm/voxel isotropic)  
#   - Dense mitochondria with complex shapes
#   - Challenging instance separation requiring precise SDT

experiment_name: betaseg_mednext_s_sdt_affinity
description: BetaSeg 3D mitochondria instance segmentation with MedNeXt using SDT+affinity (1+6 channels)

# System
system:
  training:
    num_gpus: 4
    num_workers: 8                     # Parallel data loading
    batch_size: 4                     # Larger batch for single-channel output (vs multi-task)
  inference:
    num_gpus: 4
    num_workers: 8
    batch_size: 1
  seed: 0

# Model - MedNeXt for SDT-based mitochondria instance segmentation
model:
  architecture: mednext               # MedNeXt (SOTA for instance segmentation)

  # Input/output configuration
  input_size: [128, 128, 128]          # Isotropic patches for isotropic data (16×16×16 nm)
  output_size: [128, 128, 128]
  in_channels: 1                      # Grayscale EM
  out_channels: 7                     # 6 affinity + 1 

  # MedNeXt architecture (optimized for instance segmentation)
  mednext_size: S                     #  S (~20-30M params) - small model for efficient training
  mednext_kernel_size: 3              # Using kernel size 3 (from nnUNet/BANIS baseline). Larger kernels (5 or 7) may improve context but increase memory usage.
  mednext_dim: "3d"                   # 3D convolutions
  deep_supervision: true              # CRITICAL for MedNeXt (5-scale deep supervision)


  # Multi-task loss configuration
  losses:
    - function: WeightedBCEWithLogitsLoss  # for affinity channels
      weight: 1.0
      pred_slice: [0, 6]
      target_slice: [0, 6]
    - function: WeightedMSELoss            # for SDT channel
      weight: 1.0
      kwargs: {tanh: true}                 # tanh activation for [-1, 1] range
      pred_slice: [6, 7]
      target_slice: [6, 7]
data:
  # Dataset configuration - BetaSeg training data
  train_path: /projects/weilab/liupeng/banis/data/mito_data/betaSeg
  # Training: 3 volumes (high_c1 moved to validation)
  train_image:
    - "high_c3_im.tiff"
  train_label:
    - "high_c3_mito.tiff"
  train_resolution: [16, 16, 16]                      # 16nm x 16nm x 16nm isotropic
  #  Validation: 1 volume (high_c1) - for monitoring generalization
  val_path: /projects/weilab/liupeng/banis/data/mito_data/betaSeg
  val_image:
    - "high_c1_im.tiff"
  val_label:
    - "high_c1_mito.tiff"
  # val_resolution defaults to train_resolution if not specified

  # Data loading optimization
  use_preloaded_cache: false                        # Disabled to enable validation support
  use_cache: true                                   # Use MONAI caching instead (still fast!)
  cache_rate: 1.0                                   # Cache 100% of data
  persistent_workers: true                          # Keep workers alive between epochs

  # Patch configuration (isotropic cubic patches for isotropic data)
  patch_size: [128, 128, 128]
  pad_size: [16, 16, 16]                             # from resolution
  pad_mode: reflect                                 # Reflection padding at boundaries
  iter_num_per_epoch: 50
  # val_iter_num: auto-calculated based on validation volume size and patch size



  # Image normalization,  Input Normalization, If the training loss is unstable, It might be that there are too many outliers. Try to clip the outliers more: 0.005 → 0.01, 0.995 → 0.99
  image_transform:
    normalize: "0-1"                                # Min-max normalization to [0, 1]
    clip_percentile_low: 0.005                      # Clip bottom 0.5% outliers (reduces noise impact)
    clip_percentile_high: 0.995                     # Clip top 0.5% outliers (reduces saturation artifacts)


  # Multi-task label transformation
  # This generates 7 channels from instance segmentation labels:
  #   - 6 channels: affinity maps (short + long range)
  #   - 1 channel: instance SDT
  # Label transformation - Affinity maps + Signed Distance Transform for instance segmentation
  label_transform:
    targets:
      # Target 1: Affinity maps (6 channels: 3 short-range + 3 long-range)
      - name: affinity
        kwargs:
          offsets:
            # Short-range affinities (offset = 1 voxel)
            - "0-0-1"              # x-direction, distance 1
            - "0-1-0"              # y-direction, distance 1
            - "1-0-0"              # z-direction, distance 1
            # Long-range affinities (offset = 10 voxels, matching BANIS --long_range 10)
            - "0-0-10"             # x-direction, distance 10
            - "0-10-0"             # y-direction, distance 10
            - "10-0-0"             # z-direction, distance 10
        # Total: 6 affinity channels (3 short + 3 long)
      # Target 2: Signed Distance Transform (1 channel)
      - name: skeleton_aware_edt    # [1][skeleton_aware_edt]New Version of SDT; [2][signed_distance] TRUE Signed Distance Transform (solves class imbalance!); [3][instance_edt] for edt only
        kwargs:
          resolution: [16, 16, 16]     # Physical voxel resolution (z, y, x)
          alpha: 0.8                     # Affinity-based (alpha=1 for skeleton-aware distance)
          bg_value: -1.0               # Background value for distance map
          relabel: true



  # Augmentation - crucial for generalization
  augmentation:
    preset: "some" # some, none, all，new version of augmentation

    affine:
      enabled: true
      prob: 0.5
      rotate_range: [0.2, 0.2, 0.2]
      scale_range: [0.2, 0.2, 0.2]
      shear_range: [0.5, 0.5, 0.5]
    intensity:
      enabled: true
      gaussian_noise_prob: 0.3
      gaussian_noise_std: 0.5
      shift_intensity_prob: 0.3
      shift_intensity_offset: 0.1
      contrast_prob: 0.3
      contrast_range: [0.7, 1.4]


    missing_section:
      enabled: true
      prob: 0.05
      num_sections: 2

    misalignment:
      enabled: true
      prob: 0.05
      displacement: 10
      rotate_ratio: 0.0

    flip:
      enabled: true
      prob: 0.5

    rotate:
      enabled: true
      prob: 0.5

    elastic:
      enabled: true
      prob: 0.3


# Optimizer - MedNeXt recommended settings
optimization:
  max_steps: 1000000
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  precision: "16-mixed"                 # FP16 mixed precision (better GPU compatibility than bf16)，"16-mixed"   

  optimizer:
    name: AdamW
    lr: 1e-3                           # MedNeXt recommended: 1e-3 (constant LR)
    weight_decay: 1e-2
    betas: [0.9, 0.999]
    eps: 1.0e-4                      # 1.0e-8 -> 1.0e-4. 1e-8 cause nans in fp16

  # Scheduler - Constant LR (MedNeXt recommendation)
  scheduler:
    name: constant                      # Constant LR works best for MedNeXt (per paper)


monitor:
  # Loss monitoring and validation frequency
  detect_anomaly: false
  logging:
    # Scalar loss monitoring
    scalar:
      loss: [train_loss_total_epoch, val_loss_total_epoch, train_loss_affinity_total, train_loss_sdt_total]
      loss_every_n_steps: 100            # Log every 50 steps
      val_check_interval: 1.0           # Validate every epoch
      benchmark: true

    # Visualization - SDT predictions (train + validation)
    images:
      enabled: true
      max_images: 10                     # Show more samples for quality check
      num_slices: 10                     # More slices for 3D visualization
      log_every_n_epochs: 5             # Visualize every 5 epochs
      channel_mode: all                 # Show SDT channel
      selected_channels:

  # Checkpointing -  Save best models based on validation loss
  checkpoint:
    monitor: val_loss_total             #  Monitor validation loss (prevents overfitting)
    mode: min                           # Minimize validation loss
    save_top_k: 10                       # Keep top 5 checkpoints
    save_last: true
    save_every_n_epochs: 5             # Save checkpoint every 5 epochs
    dirpath: outputs/betaseg_mednext_affinity_sdt/checkpoints/
    use_timestamp: true

  # Early stopping -  Stop training when validation loss plateaus
  early_stopping:
    enabled: true
    monitor: val_loss_total             #  Monitor validation loss (prevents overfitting)
    patience: 150                       # More patience for SDT convergence
    mode: min
    min_delta: 1e-6                     # Small delta for precise SDT
    check_finite: true
    threshold: 0.01
    divergence_threshold: 100.0

# Inference - MONAI SlidingWindowInferer for BetaSeg
test:
  data:
    test_image: /projects/weilab/liupeng/banis/data/mito_data/betaSeg/high_c2_im.tiff
    test_label: /projects/weilab/liupeng/banis/data/mito_data/betaSeg/high_c2_mito.tiff
    test_resolution: [16, 16, 16]
    output_path: outputs/betaseg_mednext_affinity_sdt/results/

    #  Inference normalization (must match training normalization!)
    image_transform:
      normalize: "0-1"                              # Min-max normalization [0,1] (same as training)
      clip_percentile_low: 0.005                    # Clip bottom 0.5% outliers (same as training)
      clip_percentile_high: 0.995                   # Clip top 0.5% outliers (same as training)
  # Decoding configuration (SDT → instances via watershed)
  decoding:
    - name: decode_distance_watershed  # ← Changed from decode_instance_binary_contour_distance
      kwargs:
        distance_channels: [6]            # Use SDT channel only for now
        distance_threshold: [0.5, 0]       # Seeds: SDT>0.5, Foreground: SDT>0
        min_seed_size: 100
        min_instance_size: 50
        use_fast_edt: true                 # Enable fast EDT (10-50x speedup)
        edt_parallel: 8                    # Use 8 CPU cores
        edt_downsample_factor: 1           # Full resolution (use 2 for large volumes)

  # Evaluation
  evaluation:
    enabled: true
    metrics: [adapted_rand, voi, instance_accuracy, instance_accuracy_detail]          # Adapted Rand Score + VOI + Accuracy for instance segmentation


inference:
  # MONAI SlidingWindowInferer parameters
  sliding_window:
    window_size: [128, 128, 128]         # Match training patch size
    sw_batch_size: 4                    # Process multiple patches per batch
    overlap: 0.5                        # 50% overlap for smooth blending
    blending: gaussian                  # Gaussian weighting for smooth blending
    sigma_scale: 0.25                   # Gaussian sigma scale
    padding_mode: replicate             # Replicate padding at volume boundaries

  # Test-Time Augmentation (TTA) for SDT
  test_time_augmentation:
    flip_axes:                          # Use all 8 flip augmentations (2^3 for xyz)
    rotation90_axes:                    # No 90-degree rotations
    channel_activations:
      - [0, 6, sigmoid]               # Affinity channels: sigmoid activation
      - [6, 7, tanh]
    select_channel: all
    ensemble_mode: mean                 # Average predictions across augmentations
    apply_mask: false                   # No mask for BetaSeg

  # Save intermediate predictions
  save_prediction:
    enabled: true                       # Save SDT predictions before decoding
    intensity_scale: -1                 # Keep original scale (no rescaling)
    intensity_dtype: float32            # Keep as float32 for SDT
    output_formats: [h5]
