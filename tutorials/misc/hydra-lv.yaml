# Hydra Large Vesicle Segmentation with MONAI Residual UNet
# Multi-task learning: Binary + Boundary + Distance
#
# ============================================================================
# ARCHITECTURE SELECTION - Change 'architecture' to switch models:
# ============================================================================
#
# monai_unet (recommended for MONAI)
#   - MONAI's UNet with residual units
#   - Supports any number of levels (uses filters directly)
#   - No deep supervision
#   - Recommended for: MONAI baseline, flexible architecture
#
# monai_basic_unet3d
#   - MONAI's BasicUNet (always 6 levels, pads filters if < 6)
#   - Simple, fast
#   - Recommended for: Quick experiments
#
# rsunet
#   - Residual Symmetric U-Net (EM-optimized)
#   - No checkerboard artifacts (uses upsample+conv instead of transposed conv)
#   - Anisotropic convolutions for EM data
#   - Recommended for: Production EM segmentation, anisotropic data
#
# mednext
#   - MedNeXt (MICCAI 2023, ConvNeXt-based)
#   - State-of-the-art performance
#   - Deep supervision for better training
#   - Sizes: S (5.6M), B (10.5M), M (17.6M), L (61.8M) params
#   - Recommended for: Best accuracy, sufficient GPU memory
#
# ============================================================================
#
# This config uses multi-task learning to predict:
#   - Channel 0: Binary masks (sigmoid activation)
#   - Channel 1: Boundary maps (sigmoid activation)
#   - Channel 2: Distance transforms (tanh activation)
#
# Multi-task setup uses different loss functions for each channel:
#   - Binary & Boundary: DiceLoss + BCEWithLogitsLoss
#   - Distance: WeightedMSELoss
#
# Valid region masks (train_mask, val_mask):
#   - Masks define valid regions for loss computation
#   - Applied after same augmentation as labels (spatial consistency)
#   - Loss is only computed in valid (mask=1) regions

experiment_name: hydra-lv_rsunet
description: Hydra large vesicle segmentation with RSUNet (EM-optimized) and multi-task learning

# System
system:
  training:
    num_gpus: 4
    num_workers: 2                     # More workers for parallel data loading (6x speedup)
    batch_size: 8                      # Reduced from 32 for larger patches (OPTION 3)
  inference:
    num_gpus: 1
    num_workers: 1
    batch_size: 1
  seed: 42

# Model Configuration
model:
  # ========== CHANGE THIS LINE TO SWITCH ARCHITECTURES ==========
  architecture: rsunet  # Options: monai_unet, monai_basic_unet3d, rsunet, mednext
  # ==============================================================
  # OPTION 2: Using RSUNet (EM-optimized architecture)
  #   - Optimized for anisotropic EM data (30nm Z, 8nm XY)
  #   - No checkerboard artifacts (cleaner boundaries)
  #   - Better gradient flow with residual connections
  #   - Expected improvement: +2-3% accuracy over monai_unet
  #
  # OPTION 3: Larger patch size for better context
  #   - Increased from [24, 96, 96] to [32, 128, 128]
  #   - Better spatial context for large vesicles
  #   - Expected improvement: +2-4% accuracy
  #   - Note: Requires more GPU memory, batch size reduced

  # Common settings (used by all architectures)
  input_size: [32, 128, 128]           # 32x128x128 input patches (OPTION 3)
  output_size: [32, 128, 128]          # 32x128x128 output patches
  in_channels: 1
  out_channels: 3                      # 3 channels: binary, boundary, distance

  # UNet architecture configuration (optimized for 32x128x128)
  filters: [32, 64, 128, 256, 512]     # 5 filter stages (4 encoder + 1 bottleneck)
  strides: [2, 2, 2]                   # 3×2 downsampling → minimum dimension: 4×16×16
  num_res_units: 2                     # Residual units per block
  kernel_size: 3                       # Convolution kernel size
  norm: batch
  dropout: 0.1                         # Dropout for regularization

  # MONAI BasicUNet-specific settings (ignored by other architectures)
  upsample: nontrainable                # Use trilinear upsampling (no transposed conv)

  # RSUNet-specific settings (ignored by other architectures)
  rsunet_norm: batch                    # Batch normalization for RSUNet

  # MedNeXt-specific settings (ignored by other architectures)
  mednext_size: S                       # S (5.6M), B (10.5M), M (17.6M), L (61.8M)
  mednext_kernel_size: 3                # 3, 5, or 7
  deep_supervision: false               # Enable deep supervision for MedNeXt

  # Multi-task loss configuration
  # Adaptive balancing with uncertainty weighting across binary / boundary / distance heads
  loss_functions: [DiceLoss, WeightedBCEWithLogitsLoss, DiceLoss, TverskyLoss, SmoothL1Loss]
  loss_weights: [1.0, 1.0, 1.0, 1.0, 1.0]       # Base weights; adaptive weighting will balance tasks
  loss_kwargs:
    - {sigmoid: true, smooth_nr: 1e-5, smooth_dr: 1e-5}  # DiceLoss for binary
    - {reduction: mean}                            # WeightedBCEWithLogitsLoss: average over batch
    - {sigmoid: true, smooth_nr: 1e-5, smooth_dr: 1e-5}  # DiceLoss for boundary
    - {sigmoid: true, alpha: 0.7, beta: 0.3, smooth_nr: 1e-5, smooth_dr: 1e-5}  # Tversky handles sparse contours
    - {beta: 0.1, reduction: mean, tanh: true}                       # SmoothL1 for distance (with tanh activation)

  # Adaptive loss balancing between heads
  loss_balancing:
    strategy: uncertainty           # Options: null, uncertainty, gradnorm

  # Multi-task loss terms (explicit channel/target routing)
  # Format: list of {loss_index, pred_slice, target_slice, task_name, ...}
  loss_terms:
    - name: label_loss_0
      loss_index: 0
      pred_slice: [0, 1]
      target_slice: [0, 1]
      task_name: label
    - name: label_loss_1
      loss_index: 1
      pred_slice: [0, 1]
      target_slice: [0, 1]
      task_name: label
    - name: boundary_loss_2
      loss_index: 2
      pred_slice: [1, 2]
      target_slice: [1, 2]
      task_name: boundary
    - name: boundary_loss_3
      loss_index: 3
      pred_slice: [1, 2]
      target_slice: [1, 2]
      task_name: boundary
    - name: edt_loss_4
      loss_index: 4
      pred_slice: [2, 3]
      target_slice: [2, 3]
      task_name: edt
data:
  # Volume configuration - supports multiple files via glob pattern or list
  train_image: "datasets/hydra-lv/vol*_im.h5"     # Training volumes
  train_label: "datasets/hydra-lv/vol*_vesicle_ins.h5"     # Training labels
  train_mask: "datasets/hydra-lv/vol*_mask.h5"     # Training masks
  train_resolution: [30, 8, 8]   # Hydra: 30nm (Z) x 8nm (XY) anisotropic resolution
  use_preloaded_cache: true           # Pre-load raw volumes into RAM for fast random cropping
  cache_rate: 0.0                     # No MONAI caching (augmentation is on-the-fly, random crops change)
  persistent_workers: true            # Keep workers alive between epochs (avoid restart overhead)

  # Patch configuration
  patch_size: [32, 128, 128]           # 32x128x128 training patches (OPTION 3 - larger for better context)
  pad_size: [8, 24, 24]                # Reflection padding for context (scaled proportionally)
  pad_mode: reflect                    # Reflection padding at boundaries
  iter_num_per_epoch: 1280              # More iterations for smaller patches
  # Image normalization
  image_transform:
    normalize: "0-1"                   # Min-max normalization to [0, 1]
    clip_percentile_low: 0.0           # No clipping
    clip_percentile_high: 1.0

  # Label transformation for multi-task learning
  label_transform:
    targets:
      - name: binary                # Channel 0: foreground mask
      - name: instance_boundary     # Channel 1: contour map
        kwargs:
          thickness: 1
          edge_mode: "all"
          mode: "2d"
      - name: instance_edt          # Channel 2: distance transform (bbox-optimized)
        kwargs:
          mode: "3d"              # 2D EDT with per-instance bounding box optimization
          quantize: false

  # Augmentation - comprehensive set for large vesicle segmentation
  # Note: When enabled, augmentations (rotation, flip, etc.) are applied to:
  #   - image: geometric + intensity transforms
  #   - label: same geometric transforms as image
  #   - mask: same geometric transforms as image and label
  # This ensures spatial consistency across image/label/mask triplets
  augmentation:
    preset: "some"  # Enable only augmentations explicitly set to enabled=True

    # Standard geometric augmentations (safe for 3D EM)
    flip:
      enabled: true
      prob: 0.5
      spatial_axis: [0, 1, 2]  # Flip x/y/z

    rotate:
      enabled: true
      prob: 0.5
      spatial_axes: [1, 2]  # Rotate Y-X plane (preserves Z-axis)

    affine:
      enabled: true
      prob: 0.3  # Lower prob to avoid too aggressive transforms
      rotate_range: [0.1, 0.1, 0.1]  # Small rotations (~6°)
      scale_range: [0.05, 0.05, 0.05]  # Small scaling (±5%)
      shear_range: [0.05, 0.05, 0.05]  # Small shearing

    # Intensity augmentations (important for EM data variability)
    intensity:
      enabled: true
      gaussian_noise_prob: 0.2  # Moderate noise
      gaussian_noise_std: 0.03
      shift_intensity_prob: 0.4
      shift_intensity_offset: 0.1
      contrast_prob: 0.4
      contrast_range: [0.8, 1.2]  # Moderate contrast variation

    # EM-specific augmentations (highly recommended for EM data)
    misalignment:
      enabled: true
      prob: 0.4
      displacement: 8  # Moderate displacement
      rotate_ratio: 0.3  # Mix of translation and rotation

    missing_section:
      enabled: true
      prob: 0.3
      num_sections: 2  # 1-2 missing sections (common in EM)

    motion_blur:
      enabled: true
      prob: 0.3
      sections: 2
      kernel_size: 9  # Moderate blur

# Optimizer - AdamW with improved hyperparameters
optimization:
  max_epochs: 10000
  gradient_clip_val: 0.5               # Conservative gradient clipping (from lucchi++)
  accumulate_grad_batches: 2           # Effective global batch ≈32 with 4 GPUs × bs=4
  precision: "bf16-mixed"              # BFloat16 mixed precision

  optimizer:
    name: AdamW
    lr: 0.0005                         # Lower LR pairs better with warmup+cosine
    weight_decay: 0.01
    betas: [0.9, 0.999]
    eps: 1.0e-8

  # Scheduler - linear warmup into cosine decay (smoother than flat LR + ReduceLROnPlateau)
  scheduler:
    name: warmupcosine
    warmup_epochs: 200                # Linear ramp to target LR
    warmup_start_lr: 0.1              # Start at 10% of base LR
    min_lr: 1.0e-6                    # Eta min for cosine tail

  # Exponential Moving Average (EMA) weights for stabler validation
  ema:
    enabled: true
    decay: 0.999
    warmup_steps: 1000                # Sync EMA to model for the first N updates
    validate_with_ema: true

monitor:
  # Loss monitoring and validation frequency  
  detect_anomaly: false
  logging:
    # scalar loss
    scalar:
      loss: [train_loss_total_epoch]
      loss_every_n_steps: 10
      val_check_interval: 1.0
      benchmark: true

    # visualization
    images:
      enabled: true
      max_images: 2
      num_slices: 4
      log_every_n_epochs: 1
      channel_mode: all                 # Show all 3 channels for multi-task
      selected_channels:

  # Checkpointing
  checkpoint:
    mode: min
    save_top_k: 3
    save_last: true
    save_every_n_epochs: 10
    dirpath: outputs/hydra-lv_rsunet/checkpoints/
    use_timestamp: true

  # Early stopping - Patient for convergence (improved from lucchi++)
  early_stopping:
    enabled: true
    monitor: train_loss_total_epoch
    patience: 100        # Reduced from 300 for faster convergence detection
    mode: min
    min_delta: 1.0e-4    # Minimum delta for improvement
    check_finite: true   # Stop if monitored metric becomes NaN/inf
    threshold: 0.02      # Stop if loss gets this low (excellent convergence)
    divergence_threshold: 100.0  # Stop if loss exceeds this (training collapse - very high value)

# ============================================================================
# INFERENCE CONFIGURATION
# ============================================================================
#
# TWO-STAGE INFERENCE WORKFLOW:
#
# STAGE 1: Parameter Tuning (Optuna on hydra-lv test data with ground truth)
#   - Run: python scripts/tune_decoding.py --config tutorials/hydra-lv.yaml
#   - Uses: datasets/hydra-lv/vol*_*.h5 (current test data with ground truth)
#   - Optimizes: Decoding parameters (thresholds, min_instance_size, etc.)
#   - Metric: adapted_rand (higher is better)
#   - Output: outputs/optuna-lv_tuning/best_params.yaml
#
# STAGE 2: Final Testing (on bouton-lv train data with optimized parameters)
#   - Run: python scripts/main.py --config tutorials/hydra-lv.yaml --mode test
#   - Uses: datasets/bouton-lv/train/vol0_*.h5 (final test set)
#   - Applies: Optimized parameters from Stage 1
#   - Metric: adapted_rand evaluation
#
# ============================================================================

# ============================================================================
# SHARED INFERENCE CONFIGURATION
# ============================================================================
# This section contains inference settings that are shared by:
# 1. STAGE 1 (Optuna tuning on hydra-lv data)
# 2. STAGE 2 (Final testing on bouton-lv data)
# Both stages use the same sliding window and TTA settings for consistency.
# ============================================================================
inference:
  # MONAI SlidingWindowInferer parameters
  sliding_window:
    window_size: [32, 128, 128]        # Match training patch size (OPTION 3)
    sw_batch_size: 1                   # Process 1 patch at a time (memory optimization)
    overlap: 0.25                      # 25% overlap (reduced from 0.5 to save memory)
    blending: gaussian                 # Gaussian weighting for smooth blending
    sigma_scale: 0.25                  # Larger sigma = smoother blending at boundaries
    padding_mode: replicate            # Replicate edge values (better than reflect for z=0)

  # Test-Time Augmentation (TTA)
  test_time_augmentation:
    flip_axes:           # Use all flip augmentations
    # Rotation90 augmentation (optional, can significantly increase inference time)
    # Options:
    #   null: No rotation augmentation
    #   all: All possible rotation planes (3 planes for 3D: D-H, D-W, H-W)
    #   [[1, 2]]: Specific planes using spatial axes (0=D, 1=H, 2=W)
    #             e.g., [[1, 2]] for H-W plane only
    rotation90_axes:       # No rotation by default (set to "all" or [[1, 2]] to enable)
    # Per-channel activations (aligned with loss_terms)
    # Format: [[start_ch, end_ch, activation], ...]
    select_channel: all               # Use all channels
    channel_activations:
      - [0, 1, sigmoid]                # Channel 0: binary segmentation (sigmoid)
      - [1, 2, sigmoid]                # Channel 1: boundary (sigmoid)
      - [2, 3, tanh]                   # Channel 2: EDT distance (tanh)
    ensemble_mode: mean              # Mean ensemble (smooth predictions)
    apply_mask: true                   # Multiply predictions by test_mask after ensemble

  save_prediction:
    enabled: true             # Save intermediate predictions (before decoding)
    intensity_scale: -1      # Scale predictions to [0, 255] for saving    


# ============================================================================
# PARAMETER TUNING CONFIGURATION (STAGE 1)
# ============================================================================
tune:
  # Enable/disable parameter tuning
  enabled: true

  # -------------------------------------------------------------------------
  # General Settings
  # -------------------------------------------------------------------------
  n_trials: 100                         # Number of optimization trials
  timeout:                              # Timeout in seconds (null = no timeout)
  study_name: "hydra-lv_decoding_optimization"
  storage: "sqlite:///outputs/optuna_studies/hydra-lv_decoding_tuning.db"
  load_if_exists: true                  # Resume existing study if interrupted

  # -------------------------------------------------------------------------
  # Sampler Configuration (Bayesian Optimization)
  # -------------------------------------------------------------------------
  sampler:
    name: TPE                           # Tree-structured Parzen Estimator
    kwargs:
      n_startup_trials: 10              # Random trials before TPE
      n_ei_candidates: 24               # Candidates for expected improvement
      multivariate: false               # Disable for compatibility with postprocessing params

  # -------------------------------------------------------------------------
  # Pruner Configuration (Early Stopping)
  # -------------------------------------------------------------------------
  pruner:
    enabled: false                      # Disabled for post-processing

  # -------------------------------------------------------------------------
  # Optimization Objective
  # -------------------------------------------------------------------------
  optimization:
    mode: single
    single_objective:
      metric: adapted_rand              # Primary metric to optimize
      direction: minimize               # Lower is better

  # -------------------------------------------------------------------------
  # Data Configuration (tuning data with ground truth)
  # -------------------------------------------------------------------------
  data:
    tune_image: "datasets/hydra-lv/vol*_im.h5"
    tune_label: "datasets/hydra-lv/vol*_vesicle_ins.h5"
    tune_mask: "datasets/hydra-lv/vol*_mask.h5"
    tune_resolution: [30, 8, 8]         # [z, y, x] in nm      
    # Image normalization
    image_transform:
      normalize: "0-1"                   # Min-max normalization to [0, 1]
      clip_percentile_low: 0.0           # No clipping
      clip_percentile_high: 1.0


  # -------------------------------------------------------------------------
  # Output Configuration
  # -------------------------------------------------------------------------
  output:
    output_dir: "outputs/hydra-lv_rsunet/tuning"
    output_pred:                            # Will default to outputs/hydra-lv_rsunet/results
    cache_suffix: "_tta_prediction.h5"      # Suffix for prediction files
    save_all_trials: false
    save_best_segmentation: true
    save_study: true

    # Visualizations
    visualizations:
      enabled: false

    # Report generation
    report:
      enabled: true
      top_n_trials: 10
      format: markdown

  # -------------------------------------------------------------------------
  # Logging
  # -------------------------------------------------------------------------
  logging:
    verbose: true
    log_file: "outputs/hydra-lv_rsunet/optuna_hydra_lv_tuning/tuning.log"
    optuna_log_level: INFO
    show_progress_bar: true

  # -------------------------------------------------------------------------
  # Parameter Search Space
  # -------------------------------------------------------------------------
  parameter_space:
    # You can optimize parameters for multiple functions:
    # 1. Decoding function parameters
    # 2. Post-processing function parameters

    # -------------------------------------------------------------------------
    # Decoding Function Configuration
    # -------------------------------------------------------------------------
    decoding:
      function_name: decode_instance_binary_contour_distance

      # Default/fixed parameter values (used unless overridden by optimization)
      defaults:
        binary_threshold: [0.9, 0.1]
        contour_threshold: [0.8, 1.1]
        distance_threshold: [0.5, 0.0]
        min_seed_size: 8

      # Parameters to optimize (only these will be searched by Optuna)
      # Note: Each threshold is a tuple (seed_threshold, foreground_threshold)
      # The tuning script will reconstruct tuples from _seed and _foreground parameters
      parameters:
        # Binary threshold tuple: (seed_threshold, foreground_threshold)
        binary_threshold_seed:
          type: float
          range: [0.5, 1.0]
          step: 0.1
          param_group: binary_threshold
          tuple_index: 0
          description: "Binary threshold for seed generation (first value in tuple)"

        binary_threshold_foreground:
          type: float
          range: [0.0, 0.5]
          step: 0.1
          param_group: binary_threshold
          tuple_index: 1
          description: "Binary threshold for foreground mask (second value in tuple)"

        # Contour threshold tuple: (seed_threshold, foreground_threshold)
        contour_threshold_seed:
          type: float
          range: [0.5, 1.0]
          step: 0.1
          param_group: contour_threshold
          tuple_index: 0
          description: "Contour threshold for seed generation (first value in tuple)"

        contour_threshold_foreground:
          type: float
          range: [0.5, 1.1]
          step: 0.1
          param_group: contour_threshold
          tuple_index: 1
          description: "Contour threshold for foreground mask (second value in tuple)"

        # Distance threshold tuple: (seed_threshold, foreground_threshold)
        distance_threshold_seed:
          type: float
          range: [0, 1]
          step: 0.1
          param_group: distance_threshold
          tuple_index: 0
          description: "Distance threshold for seed generation (first value in tuple)"

        distance_threshold_foreground:
          type: float
          range: [-0.5, 0.5]
          step: 0.1
          param_group: distance_threshold
          tuple_index: 1
          description: "Distance threshold for foreground mask (second value in tuple)"

        # Minimum seed size (not a tuple)
        min_seed_size:
          type: int
          range: [4, 16]
          step: 4
          description: "Minimum size for watershed seeds (voxels)"


# ============================================================================
# INFERENCE (STAGE 2 - Final Testing on Bouton-LV Train Data)
# ============================================================================
test:
  data:
    # Final test data (bouton-lv train volumes with ground truth)
    test_image: datasets/bouton-lv/train/vol0_im.h5
    test_label: datasets/bouton-lv/train/vol0_lv.h5
    test_mask: datasets/bouton-lv/train/vol0_mask.h5
    # test_image: "datasets/hydra-lv/vol*_im.h5"
    # test_label: "datasets/hydra-lv/vol*_vesicle_ins.h5"
    # test_mask: "datasets/hydra-lv/vol*_mask.h5"
    test_resolution: [30, 8, 8]
    # Image normalization
    image_transform:
      normalize: "0-1"                   # Min-max normalization to [0, 1]
      clip_percentile_low: 0.0           # No clipping
      clip_percentile_high: 1.0



  # Decoding configuration (instance segmentation postprocessing)
  # NOTE: These are initial values - will be replaced by Optuna optimized values
  decoding:
    - name: decode_instance_binary_contour_distance
      kwargs:
        binary_threshold: [0.5, 0.1]
        contour_threshold: [0.8, 1.1]
        distance_threshold: [0.2, 0.0]
        min_seed_size: 8

  # Evaluation
  evaluation:
    enabled: true                        # Enable evaluation with ground truth
    metrics: [adapted_rand]             # Metrics to compute
