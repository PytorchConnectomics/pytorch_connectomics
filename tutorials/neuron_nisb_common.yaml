shared:
  arch_profile: mednext_b

_base_: bases/arch_profiles.yaml

experiment_name: neuron_nisb_common_mednext_b_sdt
description: NISB neuron instance segmentation (BANIS-style) with MedNeXt-B, affinity + SDT (40nm)

model:
  in_channels: 1
  out_channels: 7
  mednext_size: B
  mednext_kernel_size: 3
  mednext_dim: 3d
  mednext_checkpoint_style: outside_block
  deep_supervision: false

  losses:
    - function: WeightedBCEWithLogitsLoss
      weight: 1.0
      pred_slice: [0, 6]
      target_slice: [0, 6]
    - function: WeightedMSELoss
      weight: 1.0
      kwargs: {tanh: true}
      pred_slice: [6, 7]
      target_slice: [6, 7]
data:
  # BANIS command mapping:
  # --base_data_path /projects/weilab/dataset/nisb
  # --data_setting base

  # BANIS data.zarr arrays are under each seed directory.
  iter_num_per_epoch: 200

  use_preloaded_cache_train: true
  use_preloaded_cache_val: true
  use_cache: false
  persistent_workers: true

  image_transform:
    normalize: "0-1"
    clip_percentile_low: 0.0
    clip_percentile_high: 1.0

  augmentation:
    preset: some

    flip:
      enabled: true
      prob: 0.5

    rotate:
      enabled: true
      prob: 0.5

    affine:
      enabled: true
      prob: 0.5
      rotate_range: [0.5, 0.5, 0.5]
      scale_range: [0.2, 0.2, 0.2]
      shear_range: [0.2, 0.2, 0.2]

    intensity:
      enabled: true
      gaussian_noise_prob: 0.5
      gaussian_noise_std: 0.5
      shift_intensity_prob: 0.5
      shift_intensity_offset: 0.1
      contrast_prob: 0.5
      contrast_range: [0.9, 1.1]

optimization:
  max_epochs: 500
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  precision: "16-mixed"
  log_every_n_steps: 100
  val_check_interval: 10
  num_sanity_val_steps: 0

  optimizer:
    name: AdamW
    lr: 1.0e-3
    weight_decay: 1.0e-2
    betas: [0.9, 0.999]
    eps: 1.0e-8

  scheduler:
    name: CosineAnnealingLR
    t_max: 50000
    interval: step
    frequency: 1

monitor:
  logging:
    scalar:
      loss: [train_loss_total_epoch, val_loss_total, train_loss_affinity_total, train_loss_sdt_total]
      loss_every_n_steps: 100
      val_check_interval: 10.0
    images:
      enabled: true
      max_images: 8
      num_slices: 8
      log_every_n_epochs: 1
      channel_mode: all

  checkpoint:
    monitor: val_loss_total
    mode: min
    save_top_k: 5
    save_last: true
    save_every_n_epochs: 10
    use_timestamp: true

  early_stopping:
    enabled: false

test:
  data:

  decoding:
    - name: decode_affinity_cc
      kwargs:
        threshold: 0.95

  evaluation:
    enabled: false

inference:
  num_gpus: 1
  num_workers: 4
  batch_size: 4
  sliding_window:
    sw_batch_size: 4
    overlap: 0.5
    blending: gaussian
    sigma_scale: 0.25
    padding_mode: replicate
    keep_input_on_cpu: true
    sw_device: cuda
    output_device: cpu

  test_time_augmentation:
    enabled: false
    flip_axes:
    rotation90_axes:
    channel_activations:
      - [0, 6, sigmoid]
      - [6, 7, tanh]
    select_channel: [0, 1, 2, 6]
    ensemble_mode: mean
    apply_mask: false

  save_prediction:
    enabled: true
    intensity_scale: -1.0
    intensity_dtype: float32
    output_formats: [h5]

train:
  system:
    overrides:
      num_gpus: -1
      num_workers: -1
      batch_size: 4
      seed: 42
