_base_: bases/mednext.yaml

description: MitoEM 3D mitochondria instance segmentation with MedNeXt using SDT + affinity (multi-target loss)
system:
  training:    
    num_gpus: -1
    num_workers: -1
    batch_size: 4
  inference:    
    num_gpus: 1
    num_workers: 2
    batch_size: 6
  seed: 42
model:
  input_size:
  - 32
  - 256
  - 256
  output_size:
  - 32
  - 256
  - 256
  out_channels: 7
  mednext_size: M
  mednext_kernel_size: 7
  mednext_dim: 3d  
  mednext_checkpoint_style: outside_block
  deep_supervision: false
  loss_functions:
  - WeightedBCEWithLogitsLoss
  - WeightedMSELoss
  loss_weights:
  - 1.0
  - 1.0
  loss_kwargs:
  - {}
  - tanh: true
  multi_task_config:
  - - 0
    - 6
    - affinity
    - - 0
  - - 6
    - 7
    - sdt
    - - 1
data:
  train_path: /projects/weilab/dataset/mito/mitoEM/
  val_path: /projects/weilab/dataset/mito/mitoEM/
 
  train_resolution:
  - 30
  - 8
  - 8
  val_resolution:
  - 30
  - 8
  - 8
  use_preloaded_cache_train: true
  use_preloaded_cache_val: true
  cached_sampling_foreground_threshold: 0
  use_cache: false  # keep false so every batch gets fresh random crop + augmentation  
  persistent_workers: true
  patch_size:
  - 32
  - 256
  - 256
  iter_num_per_epoch: 200
  image_transform:
    clip_percentile_low: 0.005
    clip_percentile_high: 0.995
  label_transform:
    targets:
    - name: affinity
      kwargs:
        long_range: 5
    - name: skeleton_aware_edt
      kwargs:
        resolution:
        - 30
        - 8
        - 8
        alpha: 1
        bg_value: -1.0
        relabel: true    
  augmentation:
    preset: some
    flip:
      enabled: true
    rotate:
      enabled: true
    elastic:
      enabled: true
    intensity:
      enabled: true
optimization:
  max_epochs: 500
  accumulate_grad_batches: 1
  val_check_interval: 5
  num_sanity_val_steps: 0
  precision: bf16-mixed
  deterministic: false
  benchmark: true
  optimizer:
    lr: 0.0003
    weight_decay: 1e-4
    eps: 1.0e-08
  scheduler:
    name: WarmupCosineLR
    warmup_epochs: 20
    warmup_start_lr: 3.0e-05
    min_lr: 1.0e-06
    interval: epoch
    frequency: 1
  ema:
    enabled: true
    decay: 0.999
    warmup_steps: 500
    validate_with_ema: true
monitor:
  logging:
    scalar:
      loss:
      - train_loss_total_epoch
      - val_loss_total
      - train_loss_affinity_total
      - train_loss_sdt_total
      loss_every_n_steps: 100
    images:
      max_images: 4
      num_slices: 8
      log_every_n_epochs: 10
  checkpoint:
    monitor: val_loss_total
    save_top_k: 5
    save_every_n_epochs: 10
  early_stopping:
    enabled: false
test:
  data:
    test_resolution:
    - 30
    - 8
    - 8
inference:
  sliding_window:
    window_size:
    - 32
    - 256
    - 256
    sw_batch_size: 4
    overlap: 0.5
    blending: gaussian
    sigma_scale: 0.25
    padding_mode: replicate
  test_time_augmentation:
    enabled: true
    rotation90_axes: null
    channel_activations:
    - - 0
      - 6
      - sigmoid
    - - 6
      - 7
      - tanh
    select_channel: all
    apply_mask: false
  save_prediction:
    enabled: true
    intensity_scale: -1
    intensity_dtype: float32
  decoding:
  - name: decode_distance_watershed
    kwargs:
      distance_threshold:
      - 0.5
      - 0
      min_instance_size: 100
      min_seed_size: 50
      prediction_scale: 1
  evaluation:
    enabled: true
    metrics:
    - adapted_rand
    - voi
